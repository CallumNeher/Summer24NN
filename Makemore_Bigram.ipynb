{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b94f46f-0d2a-4f87-9ad5-6800e8816263",
   "metadata": {},
   "source": [
    "__Makemore__\n",
    "Makemore is a character level language model. It treats everything as sequences of characters, predicting the most likely next character."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e53a56-72e4-46b6-a725-3591f49b2cc4",
   "metadata": {},
   "source": [
    "Building a Bigram model, for now (only looking at previous character to predict the next one (bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a067d167-4836-4fa9-a8a7-1e8f7a5fc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef5d1eb1-1a91-4393-ab99-6938c4e5fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~32000 names\n",
    "words = open('names.txt','r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7532be-5576-4eda-a846-9f25823ab896",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27), dtype = torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbf15a8-d006-4fd5-b0f5-43d8b2b6b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#character list\n",
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23e71c13-f0f5-4b06-9037-e1e051f433ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer\n",
    "tokenizer = {}\n",
    "for i in range(len(chars)):\n",
    "    tokenizer[chars[i]] = i+1\n",
    "\n",
    "tokenizer['.'] = 0 # add start and end character\n",
    "rev_tokenizer = { i:c for c,i in tokenizer.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3119a803-417f-47b0-a34e-462095e3d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77612d14-d681-4969-8855-d1d399dfa368",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = tokenizer[ch1]\n",
    "        ix2 = tokenizer[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9499c658-92f7-4450-9e57-94f506e1fd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create one probability dist.\n",
    "p = N[0].float()\n",
    "p = p / p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e14c67a5-51fc-4856-9737-cae65657cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a probability matrix, N+1 for model smoothing to avoid infinite loss\n",
    "P = (N+1).float() #keepdim below is necessary so that dimensions line up correctly \n",
    "P /= P.sum(1, keepdim = True) #sum of all rows column vector, division works because of favorable BROADCASTING rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cbc32f1-17cc-4f6c-92ec-344911a392b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "#Probability matrix trained model\n",
    "for i in range(5):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "        p=P[ix]\n",
    "        ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
    "        out.append(rev_tokenizer[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28f1e4f6-3d79-42f8-8dab-e178d5cb24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juwjdvdipkcqaz.\n",
      "p.\n",
      "cfqywocnzqfjiirltozcogsjgwzvudlhnpauyjbilevhajkdbduinrwibtlzsnjyievyvaftbzffvmumthyfodtumjrpfytszwjhrjagq.\n",
      "coreaysezocfkyjjabdywejfmoifmwyfinwagaasnhsvfihofszxhddgosfmptpagicz.\n",
      "rjpiufmthdt.\n",
      "rkrrsru.\n",
      "iyumuyfy.\n",
      "mjekujcbkhvupwyhvpvhvccragr.\n",
      "wdkhwfdztta.\n",
      "mplyisbxlyhuuiqzavmpocbzthqmimvyqwat.\n"
     ]
    }
   ],
   "source": [
    "#completely untrained (random) model\n",
    "#base case for a completely randomly generated model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "        p = torch.ones(27)/27\n",
    "        ix = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
    "        out.append(rev_tokenizer[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1a7bf8b-2eaa-4b75-aa57-8171212ba7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood = tensor(-559943.5000)\n",
      "nll = tensor(559943.5000)\n",
      "avg_nll = tensor(2.4543)\n"
     ]
    }
   ],
   "source": [
    "#Analyzing performance of first model\n",
    "log_likelihood = 0\n",
    "n = 0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = tokenizer[ch1]\n",
    "        ix2 = tokenizer[ch2]\n",
    "        prob = P[ix1,ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelihood += logprob\n",
    "        n+=1\n",
    "\n",
    "print(f'{log_likelihood = }')\n",
    "nll = -log_likelihood\n",
    "print(f'{nll = }')\n",
    "avg_nll = nll/n\n",
    "print(f'{avg_nll = }') #bug encountered where loss becomes infinite when given token combo isnt in orignial dataset (p=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9972e7a8-bc01-4cc4-9320-824ef2878814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likelihood = product of probabilities (want to maximize for a good model)\n",
    "#log likelihood: more wieldy number, sum of logs of probabilities, want to be zero (not a loss function)\n",
    "#negative log likelihood: useful such that loss is actually minimized (not maximized), usually given as an avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909e449-dcdb-4680-9faf-e96ed1117e68",
   "metadata": {},
   "source": [
    "__Use gradient based optimization to tune params of NN:__\n",
    "minimize NLL function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3b567e86-10f9-414e-95f6-b7b95a6d7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of examples 228146\n"
     ]
    }
   ],
   "source": [
    "#Training set\n",
    "xs,ys = [],[]\n",
    "num = 0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        ix1 = tokenizer[ch1]\n",
    "        ix2 = tokenizer[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        num += 1\n",
    "        \n",
    "print('Num of examples', num)\n",
    "\n",
    "xs = torch.tensor(xs) #use lowercase tensor, maintains integer dtype\n",
    "ys = torch.tensor(ys)\n",
    "W = torch.randn((27,27), generator = g, requires_grad = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1194c19-8567-4f18-91b0-d21394a53db6",
   "metadata": {},
   "source": [
    "__Model Smoothing note:__\n",
    "incentivizing W (initialized randomly here^) to start near zero is equivalent to model smoothing. more incentive for W to be near zero means smoother distribution.\n",
    "Regularization!\n",
    "\n",
    "We can build this into the loss function (0.01*(W**2.mean())). Now the optimization is simultaneously minimizing the distance between actual and predicted values, and also making weights closer together (smoothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acf73ba1-2865-4b8a-86d6-9d0e53a5d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding (vectorize integers)\n",
    "xenc = F.one_hot(xs, num_classes = 27).float() #must input float dtype into NN\n",
    "yenc = F.one_hot(ys, num_classes = 27).float()\n",
    "# one hot encoding allows us to essentially index into a row and take that row as our logits\n",
    "#works by have 1 in indexed position and zero everywhere else in a matrix product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b24a5df-3300-4bfd-99e4-54939cc18942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.48299241065979\n"
     ]
    }
   ],
   "source": [
    "#TRAINING NEURAL NET MODEL\n",
    "for k in range(100): \n",
    "    #forward pass\n",
    "    logits = xenc @ W #log-counts\n",
    "    counts = logits.exp() #counts\n",
    "    probs = counts / counts.sum(1, keepdims = True) #probability distribution\n",
    "    loss = -probs[torch.arange(num),ys].log().mean() + 0.01*((W**2).mean()) #probabilities of next character\n",
    "    #backward pass:\n",
    "    W.grad = None\n",
    "    loss.backward() #like micrograd, pytorch builds a graph of operations and back propagates loss\n",
    "    #update\n",
    "    W.data += -50 * W.grad #learning rate\n",
    "print(loss.item()) #expect this loss to be abt same as simple counts optimization (no new information)\n",
    "#using gradient based optimization here as opposed to counts based\n",
    "#gradient approach is much more flexible and can become much more complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6288f7-71a8-4036-973c-60d25ac3114a",
   "metadata": {},
   "source": [
    "__Summary thus far:__\n",
    "\n",
    "FORWARD PASS: Input letters, one hot encode, feed into NN, outputs logits (z-scores but for discrete (Bernoulli) distribution, [exponentiate into counts, convert into probabilities,] = SOFTMAX probabilities represent likelihood of next character. Softmax makes NN logits into probabilities.\n",
    "\n",
    "Can take the prob assigned by NN to actual next character as input to the loss func (Gradient Descent time!)\n",
    "\n",
    "NN Structure = single layer followed by softmax (not an MLP)\n",
    "\n",
    "BACKWARD PASS: back propagate through map of functions\n",
    "\n",
    "UPDATE: can choose a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "516dfaa1-b764-40c9-9f12-54af5c3165c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cfay.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "#Sampling from NN model\n",
    "\n",
    "for i in range(5):\n",
    "    out = []\n",
    "    ix = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes = 27).float()\n",
    "        logits = xenc @ W #predict logits\n",
    "        counts = logits.exp()\n",
    "        p = counts/counts.sum(1,keepdims = True) #probabilities for next letter\n",
    "        ix = torch.multinomial(p,num_samples = 1, replacement = True, generator = g).item()\n",
    "        out.append(rev_tokenizer[ix])\n",
    "        if ix==0:\n",
    "            break\n",
    "    print(''.join(out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37517b1a-f4f9-414b-8621-54d639f5ea1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
